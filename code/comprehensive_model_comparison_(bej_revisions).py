# -*- coding: utf-8 -*-
"""Comprehensive Model Comparison (BEJ Revisions)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ONDF8u_qt5zMaZYtRy9V4dKrTaRhb2AO
"""

!pip install prophet

# CORRECTED: Comprehensive AI & Baseline Model Comparison for BEJ Revisions
# All critical bugs fixed, fully tested structure

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings

from sklearn.model_selection import TimeSeriesSplit, GridSearchCV
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error
from statsmodels.tsa.api import SARIMAX
from prophet import Prophet
from xgboost import XGBRegressor

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, GRU, Dense, Conv1D, MaxPooling1D, Flatten, Input
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping

warnings.filterwarnings('ignore')
np.random.seed(42)
tf.random.set_seed(42)

print("✓ All libraries imported successfully.\n")

# ============================================================================
# 1. LOAD AND PREPROCESS DATA
# ============================================================================

FILE_PATH = 'RefBldgOutPatientNew2004_v1.3_7.1_2B_USA_AZ_PHOENIX.csv'
TARGET_COL = 'Electricity:Facility [kW](Hourly)'
TEST_SIZE = 24 * 14  # 14 days

try:
    df = pd.read_csv(FILE_PATH)
    print(f"✓ Dataset loaded. Shape: {df.shape}")
    print(f"  Columns: {df.columns.tolist()}\n")
except FileNotFoundError:
    print(f"✗ Error: File not found at {FILE_PATH}")
    raise

# Handle '24:00:00' entries
df['Date/Time_temp'] = df['Date/Time'].str.strip()
mask_24h = df['Date/Time_temp'].str.contains('24:00:00')
df.loc[mask_24h, 'Date/Time_temp'] = df.loc[mask_24h, 'Date/Time_temp'].str.replace('24:00:00', '00:00:00')

# Parse DateTime - Data spans 2024-01-01 to 2025-01-14
df['DateTime'] = pd.to_datetime(df['Date/Time_temp'], format='%m/%d %H:%M:%S')
# Set year to 2024, then increment for dates that roll over to next year
df['DateTime'] = df['DateTime'].apply(lambda x: x.replace(year=2024))

# Handle year transition (dates after Dec 31, 2024 -> 2025)
# This depends on your data structure; if dates restart in Jan, handle accordingly
for i in range(1, len(df)):
    if df['DateTime'].iloc[i] < df['DateTime'].iloc[i-1]:
        df.loc[i:, 'DateTime'] = df.loc[i:, 'DateTime'].apply(lambda x: x.replace(year=2025))

df.loc[mask_24h, 'DateTime'] += pd.Timedelta(days=1)

# Set index and ensure hourly frequency
df = df.set_index('DateTime').sort_index()
df = df.asfreq('h')

# Forward-fill missing values
df[TARGET_COL] = df[TARGET_COL].ffill()
df_orig = df[[TARGET_COL]].copy()

print(f"✓ Data preprocessed.")
print(f"  Date range: {df_orig.index[0]} to {df_orig.index[-1]}")
print(f"  Total samples: {len(df_orig)}\n")

# ============================================================================
# 2. FEATURE ENGINEERING
# ============================================================================

def create_features(df, target_col):
    """Create rich feature set for ML models."""
    df_feat = df.copy()

    df_feat['hour'] = df_feat.index.hour
    df_feat['dayofweek'] = df_feat.index.dayofweek
    df_feat['month'] = df_feat.index.month
    df_feat['is_weekend'] = (df_feat.index.dayofweek >= 5).astype(int)

    lags = [1, 2, 24, 168]
    for lag in lags:
        df_feat[f'lag_{lag}h'] = df_feat[target_col].shift(lag)

    df_feat['rolling_mean_24h'] = df_feat[target_col].shift(1).rolling(window=24).mean()
    df_feat['rolling_std_24h'] = df_feat[target_col].shift(1).rolling(window=24).std()

    df_feat = df_feat.dropna()
    return df_feat

df_features = create_features(df_orig, TARGET_COL)
print(f"✓ Feature engineering complete.")
print(f"  Features: {list(df_features.columns)}\n")

# ============================================================================
# 3. DATA SPLITTING & SCALING
# ============================================================================

# ML Models
X = df_features.drop(columns=[TARGET_COL])
y = df_features[TARGET_COL]

X_train, X_test = X.iloc[:-TEST_SIZE], X.iloc[-TEST_SIZE:]
y_train, y_test = y.iloc[:-TEST_SIZE], y.iloc[-TEST_SIZE:]

print(f"✓ ML Data splits:")
print(f"  Train: X={X_train.shape}, y={y_train.shape}")
print(f"  Test: X={X_test.shape}, y={y_test.shape}\n")

# Classical Models
y_train_orig, y_test_orig = df_orig.iloc[:-TEST_SIZE], df_orig.iloc[-TEST_SIZE:]

# Deep Learning Scaling
scaler_X = MinMaxScaler()
scaler_y = MinMaxScaler()

X_train_scaled = scaler_X.fit_transform(X_train)
X_test_scaled = scaler_X.transform(X_test)
y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1))

# Create 3D sequences for DL models
def create_dataset_3d(X, y, n_steps=24):
    X_3d, y_3d = [], []
    for i in range(len(X) - n_steps):
        X_3d.append(X[i:(i + n_steps)])
        y_3d.append(y[i + n_steps])
    return np.array(X_3d), np.array(y_3d)

N_STEPS = 24
n_features = X_train_scaled.shape[1]

X_train_3d, y_train_3d = create_dataset_3d(X_train_scaled, y_train_scaled, N_STEPS)
print(f"✓ 3D training data: X={X_train_3d.shape}, y={y_train_3d.shape}")

# Test 3D data with proper alignment
X_test_3d_input = np.concatenate((X_train_scaled[-N_STEPS:], X_test_scaled), axis=0)
y_test_3d_input = np.concatenate((y_train_scaled[-N_STEPS:], scaler_y.transform(y_test.values.reshape(-1, 1))), axis=0)

X_test_3d, y_test_3d = create_dataset_3d(X_test_3d_input, y_test_3d_input, N_STEPS)
X_test_3d = X_test_3d[:TEST_SIZE]
print(f"✓ 3D test data: X={X_test_3d.shape}\n")

# ============================================================================
# 4. MODEL TRAINING & EVALUATION
# ============================================================================

results = {}
predictions = pd.DataFrame(index=y_test.index)
predictions['Actual'] = y_test

# --- Model 1: Seasonal Naive ---
print("\n" + "="*60)
print("Training Model: SEASONAL NAIVE (Baseline)")
print("="*60)
y_pred_naive = df_orig[TARGET_COL].shift(168)[y_test.index]
predictions['Seasonal Naive'] = y_pred_naive

mae_naive = mean_absolute_error(y_test, y_pred_naive)
rmse_naive = np.sqrt(mean_squared_error(y_test, y_pred_naive))
results['Seasonal Naive'] = {'MAE': mae_naive, 'RMSE': rmse_naive}
print(f"✓ MAE: {mae_naive:.2f} kW | RMSE: {rmse_naive:.2f} kW")

# --- Model 2: SARIMA ---
print("\n" + "="*60)
print("Training Model: SARIMA (Baseline)")
print("="*60)
try:
    sarima_model = SARIMAX(y_train_orig,
                           order=(1, 1, 1),
                           seasonal_order=(1, 1, 1, 24),
                           enforce_stationarity=False,
                           enforce_invertibility=False)
    sarima_fit = sarima_model.fit(disp=False)
    y_pred_sarima = sarima_fit.predict(start=y_test_orig.index[0], end=y_test_orig.index[-1])
    predictions['SARIMA'] = y_pred_sarima

    mae_sarima = mean_absolute_error(y_test, y_pred_sarima)
    rmse_sarima = np.sqrt(mean_squared_error(y_test, y_pred_sarima))
    results['SARIMA'] = {'MAE': mae_sarima, 'RMSE': rmse_sarima}
    print(f"✓ MAE: {mae_sarima:.2f} kW | RMSE: {rmse_sarima:.2f} kW")
except Exception as e:
    print(f"✗ SARIMA failed: {e}")
    results['SARIMA'] = {'MAE': np.nan, 'RMSE': np.nan}

# --- Model 3: Prophet ---
print("\n" + "="*60)
print("Training Model: PROPHET")
print("="*60)
try:
    # Prepare data for Prophet
    prophet_train_df = y_train_orig.reset_index()
    prophet_train_df.columns = ['ds', 'y']

    prophet_test_df = y_test_orig.reset_index()
    prophet_test_df.columns = ['ds', 'y']

    # Initialize and fit the model
    with warnings.catch_warnings():
        warnings.simplefilter("ignore")
        model_prophet = Prophet(interval_width=0.95)
        model_prophet.fit(prophet_train_df)

    # Make predictions on test set
    future = model_prophet.make_future_dataframe(periods=len(prophet_test_df), freq='H')
    forecast = model_prophet.predict(future)

    # Extract predictions for the test set
    y_pred_prophet = forecast['yhat'].iloc[-len(prophet_test_df):].values
    predictions['Prophet'] = y_pred_prophet

    # Evaluate the model
    mae_prophet = mean_absolute_error(y_test, y_pred_prophet)
    rmse_prophet = np.sqrt(mean_squared_error(y_test, y_pred_prophet))
    results['Prophet'] = {'MAE': mae_prophet, 'RMSE': rmse_prophet}
    print(f"✓ MAE: {mae_prophet:.2f} kW | RMSE: {rmse_prophet:.2f} kW")
except Exception as e:
    print(f"✗ Prophet failed: {str(e)[:80]}...")
    results['Prophet'] = {'MAE': np.nan, 'RMSE': np.nan}

# --- Model 4: XGBoost (Tuned) ---
print("\n" + "="*60)
print("Training Model: XGBOOST (Tuned with GridSearchCV)")
print("="*60)
tscv = TimeSeriesSplit(n_splits=3)
xgb = XGBRegressor(objective='reg:squarederror', random_state=42, n_jobs=4)
param_grid_xgb = {
    'n_estimators': [500, 1000],
    'max_depth': [5, 7],
    'learning_rate': [0.01, 0.05],
    'reg_lambda': [1]
}
grid_search_xgb = GridSearchCV(xgb, param_grid_xgb, cv=tscv, scoring='neg_mean_absolute_error', verbose=0)
grid_search_xgb.fit(X_train, y_train)
best_xgb = grid_search_xgb.best_estimator_

y_pred_xgb = best_xgb.predict(X_test)
predictions['XGBoost'] = y_pred_xgb

mae_xgb = mean_absolute_error(y_test, y_pred_xgb)
rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))
results['XGBoost'] = {'MAE': mae_xgb, 'RMSE': rmse_xgb}
print(f"✓ Best params: {grid_search_xgb.best_params_}")
print(f"✓ MAE: {mae_xgb:.2f} kW | RMSE: {rmse_xgb:.2f} kW")

# ============================================================================
# 5. DEEP LEARNING MODELS
# ============================================================================

EPOCHS = 50
BATCH_SIZE = 32
dl_early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# FIX: Proper alignment for DL predictions
def dl_predict_and_evaluate(model_name, model, X_test_3d, y_test, scaler_y, N_STEPS):
    """Predict and evaluate DL model with proper index alignment."""
    print(f"\n✓ Evaluating {model_name}...")
    y_pred_scaled = model.predict(X_test_3d, verbose=0)
    y_pred = scaler_y.inverse_transform(y_pred_scaled).flatten()

    # FIX: Align predictions to last n samples of y_test
    y_test_aligned = y_test.iloc[-len(y_pred):]
    predictions.loc[y_test_aligned.index, model_name] = y_pred

    mae = mean_absolute_error(y_test_aligned, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test_aligned, y_pred))
    results[model_name] = {'MAE': mae, 'RMSE': rmse}
    print(f"  MAE: {mae:.2f} kW | RMSE: {rmse:.2f} kW")
    return model

# --- Model 6: LSTM ---
print("\n" + "="*60)
print("Training Model: LSTM")
print("="*60)
lstm_model = Sequential([
    LSTM(50, return_sequences=True, input_shape=(N_STEPS, n_features)),
    LSTM(50),
    Dense(25, activation='relu'),
    Dense(1)
])
lstm_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')

lstm_model.fit(X_train_3d, y_train_3d,
               epochs=EPOCHS, batch_size=BATCH_SIZE,
               validation_split=0.1,
               callbacks=[dl_early_stopping],
               verbose=0)

dl_predict_and_evaluate('LSTM', lstm_model, X_test_3d, y_test, scaler_y, N_STEPS)

# --- Model 7: GRU ---
print("\n" + "="*60)
print("Training Model: GRU")
print("="*60)
gru_model = Sequential([
    GRU(50, return_sequences=True, input_shape=(N_STEPS, n_features)),
    GRU(50),
    Dense(25, activation='relu'),
    Dense(1)
])
gru_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')

gru_model.fit(X_train_3d, y_train_3d,
              epochs=EPOCHS, batch_size=BATCH_SIZE,
              validation_split=0.1,
              callbacks=[dl_early_stopping],
              verbose=0)

dl_predict_and_evaluate('GRU', gru_model, X_test_3d, y_test, scaler_y, N_STEPS)

# --- Model 8: 1D-CNN (TCN-style) ---
print("\n" + "="*60)
print("Training Model: 1D-CNN (TCN-style)")
print("="*60)
cnn_model = Sequential([
    Input(shape=(N_STEPS, n_features)),
    Conv1D(filters=64, kernel_size=3, activation='relu', padding='causal'),
    Conv1D(filters=64, kernel_size=3, activation='relu', padding='causal'),
    MaxPooling1D(pool_size=2),
    Flatten(),
    Dense(50, activation='relu'),
    Dense(1)
])
cnn_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')

cnn_model.fit(X_train_3d, y_train_3d,
              epochs=EPOCHS, batch_size=BATCH_SIZE,
              validation_split=0.1,
              callbacks=[dl_early_stopping],
              verbose=0)

dl_predict_and_evaluate('1D-CNN (TCN)', cnn_model, X_test_3d, y_test, scaler_y, N_STEPS)

# ============================================================================
# 6. RESULTS & VISUALIZATION
# ============================================================================

print("\n\n" + "="*60)
print("FINAL MODEL COMPARISON")
print("="*60)
results_df = pd.DataFrame.from_dict(results, orient='index').sort_values(by='MAE')
print(results_df.to_string(float_format=lambda x: f'{x:.2f}'))

# Plot
print("\n" + "="*60)
print("Generating visualization...")
print("="*60)

plot_models = ['XGBoost', 'LSTM', 'Seasonal Naive']

fig, ax = plt.subplots(figsize=(16, 7))
ax.plot(predictions['Actual'], label='Actual', color='black', linewidth=2.5, zorder=5)

for model in plot_models:
    if model in predictions.columns:
        model_data = predictions[model].dropna()
        mae = results_df.loc[model, 'MAE']
        ax.plot(model_data.index, model_data.values,
                label=f'{model} (MAE: {mae:.2f})', linestyle='--', linewidth=1.5, alpha=0.8)

ax.set_title('Model Forecast Comparison | Test Set: Jan 2024 → Jan 2025 (Last 14 Days)',
             fontsize=14, fontweight='bold')
ax.set_xlabel('Date/Time (2024-2025)', fontsize=12)
ax.set_ylabel('Electricity [kW]', fontsize=12)
ax.legend(loc='best', fontsize=11)
ax.grid(True, alpha=0.3)
# Format x-axis to show dates clearly
import matplotlib.dates as mdates
ax.xaxis.set_major_locator(mdates.MonthLocator(interval=2))
ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

print("\n✓ Analysis complete!")

import matplotlib.pyplot as plt
import numpy as np
from math import pi
import warnings
warnings.filterwarnings('ignore')

# Data from the table
models = ['Prophet', 'XGBoost', 'LSTM', 'TCN', 'GRU', 'Neural-Tree', 'Seasonal Naive', 'SARIMA']
mae_values = [35, 12.05, 13.12, 13.92, 32.34, 33.76, 16.15, 45.95]
rmse_values = [42, 23.71, 19.66, 19.74, 40.87, 44.94, 29.28, 51.24]

# Number of variables
N = len(models)

# Compute angle for each axis
angles = [n / float(N) * 2 * pi for n in range(N)]
mae_values += mae_values[:1]
rmse_values += rmse_values[:1]
angles += angles[:1]

# Create the radar chart
fig, ax = plt.subplots(figsize=(12, 10), subplot_kw=dict(projection='polar'))

# Plot data
ax.plot(angles, mae_values, 'o-', linewidth=2, label='MAE', color='#4f81bd')
ax.fill(angles, mae_values, alpha=0.25, color='#4f81bd')

ax.plot(angles, rmse_values, 'o-', linewidth=2, label='RMSE', color='#f79646')
ax.fill(angles, rmse_values, alpha=0.25, color='#f79646')

# Fix axis to go in the same direction as clock and start from top
ax.set_theta_offset(pi / 2)
ax.set_theta_direction(-1)

# Draw axis lines for each angle and label
ax.set_xticks(angles[:-1])
ax.set_xticklabels(models, size=10)

# Set y-axis limits and labels
ax.set_ylim(0, 55)
ax.set_ylabel('Error (kW)', labelpad=30)
ax.set_title('Model Comparison - MAE and RMSE', size=16, weight='bold', pad=20)

# Add legend and grid
ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1), fontsize=11)
ax.grid(True, linestyle='--', alpha=0.7)

plt.tight_layout()
plt.savefig('model_comparison_radar.png', dpi=300, bbox_inches='tight')
plt.show()

print("Radar chart saved as 'model_comparison_radar.png'")